---
name: dev-validation
description: |
  Development cycle validation gate (Gate 5) - validates all acceptance criteria are met
  and requires explicit user approval before completion.

trigger: |
  - After review gate passes (Gate 4)
  - Implementation and tests complete
  - Need user sign-off on acceptance criteria

skip_when: |
  - Review not passed -> complete Gate 4 first
  - Already validated and approved -> proceed to completion
  - No acceptance criteria defined -> request criteria first

sequence:
  after: [ring-dev-team:dev-review]

related:
  complementary: [ring-default:verification-before-completion]

verification:
  automated:
    - command: "go test ./... 2>&1 | grep -c PASS"
      description: "All tests pass"
      success_pattern: "[1-9][0-9]*"
    - command: "cat .ring/dev-team/current-cycle.json | jq '.gates[4].verdict'"
      description: "Review gate passed"
      success_pattern: "PASS"
  manual:
    - "User has provided explicit APPROVED or REJECTED decision"
    - "All acceptance criteria have verified evidence"
    - "Validation checklist presented to user"

examples:
  - name: "Successful validation"
    context: "4 acceptance criteria, all tests pass"
    expected_flow: |
      1. Gather evidence for each criterion
      2. Build validation checklist with evidence types
      3. Present to user with APPROVED/REJECTED options
      4. User selects APPROVED
      5. Document approval, proceed to feedback loop
  - name: "Validation rejection"
    context: "AC-3 not met (response time too slow)"
    expected_flow: |
      1. Present validation checklist
      2. User identifies AC-3 failure
      3. User selects REJECTED with reason
      4. Create remediation task
      5. Return to Gate 0 for fixes
---

# Dev Validation (Gate 5)

## Overview

Final validation gate requiring explicit user approval. Present evidence that each acceptance criterion is met and obtain APPROVED or REJECTED decision.

**Core principle:** Passing tests and code review do not guarantee requirements are met. User validation confirms implementation matches intent.

## Pressure Resistance

**Gate 5 (Validation) requires EXPLICIT user approval. Pressure scenarios and required responses:**

| Pressure Type | Request | Agent Response |
|---------------|---------|----------------|
| **User Busy** | "User is busy, assume approval" | "CANNOT assume approval. Wait for explicit response. Document pending status." |
| **Tests Pass** | "Tests pass, validation redundant" | "Tests verify code works. Validation verifies it meets REQUIREMENTS. Different concerns." |
| **Minor Issues** | "Fix issues after approval" | "No partial approval. REJECTED with issues, fix first, then re-validate." |
| **Implied Approval** | "User didn't object" | "Silence ‚â† approval. Require explicit 'APPROVED' or 'REJECTED: reason'." |

**Non-negotiable principle:** User MUST respond with "APPROVED" or "REJECTED: [reason]". No other responses accepted.

## Self-Approval Prohibition

**HARD GATE:** The agent that implemented code CANNOT approve validation for that same code.

| Scenario | Allowed? | Action |
|----------|----------|--------|
| Different agent/human approves | YES | Proceed with approval |
| Same agent self-approves | NO | STOP - requires external approval |
| User explicitly approves | YES | User approval always valid |

**If you implemented the code, you CANNOT approve it. Wait for user or different reviewer.**

## Common Rationalizations - REJECTED

| Excuse | Reality |
|--------|---------|
| "User is unavailable" | Unavailability ‚â† approval. STOP and wait. Document pending. |
| "Tests prove it works" | Tests verify behavior. User validates requirements alignment. |
| "Minor issues can wait" | No partial approval. Fix issues, then revalidate. |
| "User seemed happy" | Seeming ‚â† approval. Require explicit response. |
| "Implicit approval after demo" | Demo ‚â† approval. Ask for explicit decision. |
| "User approved similar before" | Past ‚â† present. Each validation requires fresh approval. |
| "Async over sync - work in parallel" | Validation is a GATE, not async task. STOP means STOP. |
| "Continue other tasks while waiting" | Other tasks may conflict. Validation blocks ALL related work. |
| "Cost of waiting is too high" | Cost of wrong approval is higher. Wait is investment. |
| "Send message and continue" | Message sent ‚â† waiting for response. STOP until APPROVED. |
| "Looks good" = approval | "Looks good" is ambiguous. Require explicit APPROVED. |
| "User said 'sure'" | "Sure" is ambiguous. Require explicit APPROVED. |
| "No objections raised" | Lack of objection ‚â† approval. Require explicit response. |

## Red Flags - STOP

If you catch yourself thinking ANY of these, STOP immediately:

- "User is busy, I'll assume approval"
- "Tests pass, validation is redundant"
- "These minor issues can be fixed later"
- "User didn't say no, so it's approved"
- "User seemed satisfied with the demo"
- "Previous similar work was approved"
- "I'll work on other tasks while waiting"
- "Async over sync - don't block"
- "Send message and continue"
- "Cost of waiting is too high"
- "'Looks good' means approved"
- "User said 'sure'"
- "No objections = approved"

**All of these indicate Gate 5 violation. Wait for explicit "APPROVED" or "REJECTED".**

## Ambiguous Response Handling

**User responses that are NOT valid approvals:**

| Response | Status | Action Required |
|----------|--------|-----------------|
| "Looks good" | ‚ùå AMBIGUOUS | "To confirm, please respond with APPROVED or REJECTED: [reason]" |
| "Sure" / "Ok" / "Fine" | ‚ùå AMBIGUOUS | Ask for explicit APPROVED |
| "üëç" / "‚úÖ" | ‚ùå AMBIGUOUS | Emojis are not formal approval. Ask for APPROVED. |
| "Go ahead" | ‚ùå AMBIGUOUS | Ask for explicit APPROVED |
| "Ship it" | ‚ùå AMBIGUOUS | Ask for explicit APPROVED |
| "APPROVED" | ‚úÖ VALID | Proceed to next gate |
| "REJECTED: [reason]" | ‚úÖ VALID | Document reason, return to Gate 0 |
| "APPROVED if X" | ‚ùå CONDITIONAL | Not approved until X is verified. Status = PENDING. |
| "APPROVED with caveats" | ‚ùå CONDITIONAL | Not approved. List caveats, verify each, then re-ask. |
| "APPROVED but fix Y later" | ‚ùå CONDITIONAL | Not approved. Y must be addressed first. |

**When user gives ambiguous response:**
```
"Thank you for the feedback. For formal validation, please confirm with:
- APPROVED - to proceed with completion
- REJECTED: [reason] - to return for fixes

Which is your decision?"
```

**Never interpret intent. Require explicit keyword.**

## Awaiting Approval - STOP ALL WORK

**When validation request is presented:**

1. **STOP ALL WORK** on this feature, module, and related code
2. **DO NOT** proceed to documentation, refactoring, or "quick fixes"
3. **DO NOT** work on "unrelated" tasks in the same codebase
4. **WAIT** for explicit user response

**User unavailability is NOT permission to:**
- Assume approval
- Work on "low-risk" next steps
- Redefine criteria as "already met"
- Proceed with "we'll fix issues later"

**Document pending status and WAIT.**

## Approval Format - MANDATORY

**User MUST respond with exactly one of:**

‚úÖ **"APPROVED"** - All criteria verified, proceed to next gate
‚úÖ **"REJECTED: [specific reason]"** - Issues found, fix and revalidate

**NOT acceptable:**
- ‚ùå "Looks good" (vague)
- ‚ùå "üëç" (ambiguous)
- ‚ùå Silence (not a response)
- ‚ùå "Approved with minor issues" (partial = REJECTED)

**If user provides ambiguous response, ask for explicit APPROVED or REJECTED.**

## Prerequisites

Before starting this gate:
- All tests pass (Gate 3 verified)
- Code review passed (Gate 4 VERDICT: PASS)
- Implementation is complete and stable

## Steps 1-4: Evidence Collection and Validation

| Step | Action | Output |
|------|--------|--------|
| **1. Gather Evidence** | Collect proof per criterion | Table: Criterion, Evidence Type (Test/Demo/Log/Manual/Metric), Location, Status |
| **2. Verify** | Execute verification (automated: `npm test --grep "AC-X"`, manual: documented steps with Result + Screenshot) | VERIFIED/FAILED per criterion |
| **3. Build Checklist** | For each AC: Status + Evidence list + Verification method | Validation Checklist |
| **4. Present Request** | Task Summary + Validation Table + Test Results + Review Summary + Artifacts | USER DECISION block with APPROVED/REJECTED options |

**Validation Request format:**
```
VALIDATION REQUEST - [TASK-ID]
Task: [title], [description], [date]
Criteria: Table (Criterion | Status | Evidence)
Tests: Total/Passed/Failed/Coverage
Review: VERDICT + issue counts
Artifacts: Code, Tests, Docs links

USER DECISION REQUIRED:
[ ] APPROVED - proceed
[ ] REJECTED - specify: which criterion, what's missing, what's wrong
```

## Steps 5-6: Handle Decision and Document

| Decision | Actions | Documentation |
|----------|---------|---------------|
| **APPROVED** | 1. Document (Task, Approver, Date, Notes) ‚Üí 2. Update status ‚Üí 3. Proceed to feedback loop | Validation Approved record |
| **REJECTED** | 1. Document (Task, Rejector, Date, Criterion failed, Issue, Expected vs Actual) ‚Üí 2. Create remediation task ‚Üí 3. Return to Gate 0 ‚Üí 4. After fix: restart from Gate 3 ‚Üí 5. Track in feedback loop | Validation Rejected + Remediation Required records |

**Validation Record format:** Date, Validator, Decision, Criteria Summary (X/Y), Evidence Summary (tests/manual/perf), Decision Details, Next Steps

## Validation Best Practices

| Category | Strong Evidence | Weak Evidence (avoid) |
|----------|-----------------|----------------------|
| **Evidence Quality** | Automated test + assertion, Screenshot/recording, Log with exact values, Metrics within threshold | "Works on my machine", "Tested manually" (no details), "Should be fine", Indirect evidence |
| **Verifiable Criteria** | "User can login" ‚Üí test login + verify session | "System is fast" ‚Üí needs specific metric |
| | "Page loads <2s" ‚Üí measure + show metric | "UX is good" ‚Üí needs measurable criteria |

## Handling Partial Validation

If some criteria pass but others fail:

1. **Do NOT partially approve**
2. Mark entire validation as REJECTED
3. Document which criteria passed (won't need re-verification)
4. Document which criteria failed (need fixes)
5. After fixes, re-verify only failed criteria
6. Present updated checklist for approval

## Anti-Patterns

**Never:**
- Skip validation because "tests pass"
- Auto-approve without user decision
- Assume criterion is met without evidence
- Accept vague approval ("looks good")
- Proceed while awaiting decision
- Reuse old evidence for new changes

**Always:**
- Present evidence for EVERY criterion
- Require explicit APPROVED/REJECTED decision
- Document rejection reason in detail
- Track validation metrics
- Re-verify after any changes

## Execution Report

| Metric | Value |
|--------|-------|
| Duration | Xm Ys |
| Criteria Validated | X/Y |
| Evidence Collected | X automated, Y manual |
| User Decision | APPROVED/REJECTED |
| Rejection Reason | [if applicable] |
| Result | Gate passed / Returned to Gate 0 |

## Edge Cases

| Scenario | Action |
|----------|--------|
| **User Unavailable** | Document pending ‚Üí Do NOT proceed ‚Üí Set escalation ‚Üí Block task completion |
| **Criterion Ambiguity** | STOP ‚Üí Ask user to clarify ‚Üí Update AC ‚Üí Re-verify with new understanding |
| **New Requirements** | Document as new req ‚Üí Complete current validation on original AC ‚Üí Create new task ‚Üí NO scope creep |
